{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30HRRwSCAdKV"
      },
      "source": [
        "### Etapas\n",
        "1. Cria√ß√£o de features\n",
        "2. Tratamento de outliers\n",
        "3. Normaliza√ß√£o dos dados\n",
        "4. Pipeline de pr√©-processamento\n",
        "5. Separa√ß√£o em treino/teste\n",
        "6. Balanceamento dos dados\n",
        "7. Treinamento dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q4F661DIPyJH"
      },
      "outputs": [],
      "source": [
        "# @title Importa√ß√£o das bibliotecas utilizadas no programa\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Carregamento do dataset\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Cria√ß√£o de features\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Normaliza√ß√£o dos dados\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import make_column_selector\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Treinamento do modelo\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier,  AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import  AdaBoostClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "x-cs77oXAWpf",
        "outputId": "771a74c7-a2e5-4ac2-c8f4-d9f909f9b792"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_23900\\3058435906.py:25: FutureWarning: The argument 'use_nullable_dtypes' is deprecated and will be removed in a future version.\n",
            "  wildfires = pd.read_parquet(\n"
          ]
        }
      ],
      "source": [
        "# @title Carregamento do dataset\n",
        "\n",
        "# Vers√£o Google Collab\n",
        "# github_link = \"https://github.com/mfigueireddo/ciencia-de-dados/blob/ba579573c5b8a9246ca04f7da29bc2c74c8b362c/datasets/pre-pipeline_wildfires.parquet\"\n",
        "# url = github_link.replace(\"/blob/\", \"/raw/\")\n",
        "\n",
        "# local_file_path = Path(\"/content/raw_wildfires.parquet\")\n",
        "\n",
        "# # Faz uma requisi√ß√£o HTTP GET ao GitHub\n",
        "# with requests.get(url, stream=True) as request:\n",
        "\n",
        "#     request.raise_for_status() # Confere se houve √™xito\n",
        "\n",
        "#     with open(local_file_path , \"wb\") as file:\n",
        "#         for chunk in request.iter_content(chunk_size=1024*1024):\n",
        "#             if chunk:\n",
        "#                 file.write(chunk)\n",
        "\n",
        "# wildfires = pd.read_parquet(local_file_path,  engine=\"pyarrow\") # Leitura realizada com a engine pyarrow\n",
        "\n",
        "\n",
        "# Vers√£o VSCode\n",
        "file_path = \"../datasets/pre-pipeline_wildfires.parquet\"\n",
        "\n",
        "wildfires = pd.read_parquet(\n",
        "    file_path,\n",
        "    engine=\"pyarrow\",\n",
        "    use_nullable_dtypes=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KUHPbh6cZ3j8"
      },
      "outputs": [],
      "source": [
        "# @title Vari√°veis globais\n",
        "\n",
        "data_column_name = 'data'\n",
        "id_column_name = 'fire_id'\n",
        "latitude_column_name = 'latitude'\n",
        "longitude_column_name = 'longitude'\n",
        "precipitation_column_name = 'precipitacao'\n",
        "max_temperature_column_name = 'temperatura_max'\n",
        "precipitation_sum_window_column_name = 'soma_precipitacao_90_dias'\n",
        "max_temperature_mean_column_name = 'media_temp_max_90_dias'\n",
        "season_column_name = 'estacao_ano_id'\n",
        "region_column_name = 'regiao_incendio'\n",
        "target_column_name = 'houve_incendio'\n",
        "indice_queima ='indice_queima'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el_9fncgZ3j9"
      },
      "source": [
        "### 1. Cria√ß√£o de features\n",
        "<u>**Features criadas**</u>\n",
        "- Esta√ß√£o do ano\n",
        "- Regi√£o do inc√™ndio\n",
        "- Soma da precipita√ß√£o nos √∫ltimos X dias\n",
        "- M√©dia de temperatura m√°xima nos √∫ltimos X dias\n",
        "\n",
        "**Observa√ß√£o**: as features esta√ß√£o do ano baseada e regi√£o do inc√™ndio n√£o est√£o sendo utilizadas para treinar o modelo porque elas pioraram consideravelmente o resultado<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wUCqwXwyFR2O"
      },
      "outputs": [],
      "source": [
        "# @title Classe FeatureCreation\n",
        "\n",
        "window_days = 90\n",
        "\n",
        "class FeaturesCreation(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Colunas utilizadas\n",
        "        self.m_date_column = data_column_name\n",
        "        self.m_group_column = id_column_name\n",
        "        self.m_latitude_column = latitude_column_name\n",
        "        self.m_longitude_column = longitude_column_name\n",
        "        self.m_precipitation_column = precipitation_column_name\n",
        "        self.m_max_temperature_column = max_temperature_column_name\n",
        "\n",
        "        # Par√¢metros personalizados para cria√ß√£o das features\n",
        "        self.m_precipitation_window_days = window_days\n",
        "        self.m_max_temperature_window_days = window_days\n",
        "\n",
        "        # Par√¢metros do DBSCAN\n",
        "        self.mm_max_radiuskm = 1.0\n",
        "        self.m_min_samples = 5\n",
        "\n",
        "        # Objetos aprendidos no fit\n",
        "        self.m_dbscan = None\n",
        "        self.m_nearest_neighbors_core = None\n",
        "        self.m_core_labels = None\n",
        "        self.m_max_radius = None\n",
        "\n",
        "    # Convers√£o necess√°ria para o DBSCAN\n",
        "    @staticmethod\n",
        "    def convert_to_radians(latitude_or_longitude):\n",
        "        return np.radians(latitude_or_longitude.astype(float))\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_month_to_season(month):\n",
        "        if month in (12, 1, 2): return 0  # Inverno\n",
        "        if month in (3, 4, 5): return 1  # Primavera\n",
        "        if month in (6, 7, 8): return 2  # Ver√£o\n",
        "        return 3  # 9, 10, 11 -> Outono\n",
        "\n",
        "    def fit(self, dataframe, target=None):\n",
        "        dataframe = dataframe.copy()\n",
        "\n",
        "        # Desativa o DBSCAN caso n√£o haja latitude e longitude\n",
        "        missing_cols = [column for column in [self.m_latitude_column, self.m_longitude_column] if column not in dataframe.columns]\n",
        "        if missing_cols:\n",
        "            self.m_dbscan = None\n",
        "            self.m_nearest_neighbors_core = None\n",
        "            self.m_core_labels = None\n",
        "            self.m_max_radius = None\n",
        "            return self\n",
        "\n",
        "        latitude_or_longitude = dataframe[[self.m_latitude_column, self.m_longitude_column]].to_numpy()\n",
        "        latitude_or_longitude_radians = self.convert_to_radians(latitude_or_longitude)\n",
        "\n",
        "        earth_radius = 6371.0\n",
        "        self.m_max_radius = self.mm_max_radiuskm / earth_radius\n",
        "\n",
        "        dbscan = DBSCAN(eps=self.m_max_radius, min_samples=self.m_min_samples, metric='haversine')\n",
        "        dbscan.fit(latitude_or_longitude_radians)\n",
        "        self.m_dbscan = dbscan\n",
        "\n",
        "        # Treina um NearestNeighbors apenas nos pontos-core para atribui√ß√£o de novos pontos √† clusters existentes em transform()\n",
        "        core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n",
        "        if hasattr(dbscan, 'core_sample_indices_') and len(dbscan.core_sample_indices_) > 0:\n",
        "            core_mask[dbscan.core_sample_indices_] = True\n",
        "            core_points = latitude_or_longitude_radians[core_mask]\n",
        "            core_labels = dbscan.labels_[core_mask]\n",
        "\n",
        "            if len(core_points) > 0:\n",
        "                nearest_neighbors = NearestNeighbors(n_neighbors=1, metric='haversine')\n",
        "                nearest_neighbors.fit(core_points)\n",
        "                self.m_nearest_neighbors_core = nearest_neighbors\n",
        "                self.m_core_labels = core_labels\n",
        "            else:\n",
        "                self.m_nearest_neighbors_core = None\n",
        "                self.m_core_labels = None\n",
        "        else:\n",
        "            self.m_nearest_neighbors_core = None\n",
        "            self.m_core_labels = None\n",
        "\n",
        "        return self\n",
        "\n",
        "    # Rotula novos pontos\n",
        "    def assign_dbscanlabels(self, dataframe):\n",
        "\n",
        "        # Se n√£o tivemos lat/lon ou DBSCAN treinado, devolve NaN\n",
        "        if self.m_nearest_neighbors_core is None or self.m_core_labels is None or self.m_max_radius is None:\n",
        "            return pd.Series([-1] * len(dataframe), index=dataframe.index, dtype='int64')\n",
        "\n",
        "        latitude_or_longitude = dataframe[[self.m_latitude_column, self.m_longitude_column]].to_numpy()\n",
        "        latitude_or_longitude_radians = self.convert_to_radians(latitude_or_longitude)\n",
        "\n",
        "        # Atribui r√≥tulo do core mais pr√≥ximo, desde que dentro do raio\n",
        "        distances, indices = self.m_nearest_neighbors_core.kneighbors(latitude_or_longitude_radians, n_neighbors=1, return_distance=True)\n",
        "        distances = distances.reshape(-1)\n",
        "        indices = indices.reshape(-1)\n",
        "\n",
        "        labels = np.full(len(dataframe), -1, dtype='int64')\n",
        "        within = distances <= self.m_max_radius\n",
        "        labels[within] = self.m_core_labels[indices[within]]\n",
        "\n",
        "        return pd.Series(labels, index=dataframe.index, dtype='int64')\n",
        "\n",
        "    # Adiciona m√©dias m√≥veis e soma pro grupo de inc√™ndio\n",
        "    def add_temporal_rollings(self, dataframe):\n",
        "\n",
        "        # Ordena por grupo e tempo para garantir rolling correto\n",
        "        if self.m_group_column in dataframe.columns and self.m_date_column in dataframe.columns:\n",
        "            dataframe = dataframe.sort_values([self.m_group_column, self.m_date_column])\n",
        "        else:\n",
        "            # Se faltar algo, s√≥ ordena por data (se existir)\n",
        "            if self.m_date_column in dataframe.columns:\n",
        "                dataframe = dataframe.sort_values(self.m_date_column)\n",
        "\n",
        "        # Rolling de precipita√ß√£o (soma dos √∫ltimos 14 dias)\n",
        "        if self.m_precipitation_column in dataframe.columns:\n",
        "            dataframe[precipitation_sum_window_column_name] = (\n",
        "                dataframe.groupby(self.m_group_column, dropna=False)[self.m_precipitation_column]\n",
        "                  .rolling(self.m_precipitation_window_days, min_periods=1)\n",
        "                  .sum()\n",
        "                  .reset_index(level=0, drop=True)\n",
        "            )\n",
        "        else:\n",
        "            dataframe[precipitation_sum_window_column_name] = np.nan\n",
        "\n",
        "        # Rolling de temperatura m√°xima (m√©dia dos √∫ltimos 7 dias)\n",
        "        if self.m_max_temperature_column in dataframe.columns:\n",
        "            dataframe[max_temperature_mean_column_name] = (\n",
        "                dataframe.groupby(self.m_group_column, dropna=False)[self.m_max_temperature_column]\n",
        "                  .rolling(self.m_max_temperature_window_days, min_periods=1)\n",
        "                  .mean()\n",
        "                  .reset_index(level=0, drop=True)\n",
        "            )\n",
        "        else:\n",
        "            dataframe[max_temperature_mean_column_name] = np.nan\n",
        "\n",
        "        return dataframe\n",
        "\n",
        "    # Aplica transforma√ß√µes e cria as novas features\n",
        "    def transform(self, dataframe, target=None):\n",
        "\n",
        "        # Trabalha em DataFrame para manter nomes/√≠ndices\n",
        "        dataframe = pd.DataFrame(dataframe).copy()\n",
        "\n",
        "        # Esta√ß√£o do ano\n",
        "        if self.m_date_column in dataframe.columns:\n",
        "            # Garante dtype datetime\n",
        "            dataframe[self.m_date_column] = pd.to_datetime(dataframe[self.m_date_column], errors='coerce')\n",
        "            estacao = dataframe[self.m_date_column].dt.month.map(self.convert_month_to_season).astype('Int64')\n",
        "            dataframe[season_column_name] = estacao.astype('float').astype('Int64')  # evita problemas de NaN -> imputar depois\n",
        "            dataframe[season_column_name] = dataframe[season_column_name].astype('float')\n",
        "        else:\n",
        "            dataframe[season_column_name] = np.nan\n",
        "\n",
        "        # Regi√£o\n",
        "        if all(c in dataframe.columns for c in [self.m_latitude_column, self.m_longitude_column]):\n",
        "            dataframe[region_column_name] = self.assign_dbscanlabels(dataframe).astype('int64')\n",
        "        else:\n",
        "            dataframe[region_column_name] = -1\n",
        "\n",
        "        # Rollings temporais\n",
        "        dataframe = self.add_temporal_rollings(dataframe)\n",
        "\n",
        "        '''\n",
        "        for col, dtype in dataframe.dtypes.items():\n",
        "            print(f\" - {col}: {dtype}\")\n",
        "        '''\n",
        "\n",
        "        return dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXWH4spcYhkY"
      },
      "source": [
        "### 2. Tratamento de outliers\n",
        "\n",
        "<u>**Transforma√ß√£o Logar√≠tmica**</u>\n",
        "- Aplica log(x) ou log(x+constante) para valores positivos\n",
        "- Muito eficaz para dados com distribui√ß√£o assim√©trica positiva\n",
        "- Comprime valores grandes e expande valores pequenos\n",
        "- F√≥rmula: X_log = log(X + c), onde c evita log(0)\n",
        "\n",
        "<u>**Transforma√ß√£o Raiz Quadrada**</u>\n",
        "- Menos dr√°stica que a transforma√ß√£o logar√≠tmica\n",
        "- √ötil para dados de contagem e vari√°veis positivamente assim√©tricas\n",
        "- F√≥rmula: X_sqrt = sqrt(X)\n",
        "\n",
        "<u>**Winsoriza√ß√£o (Capping/Clipping)**</u>\n",
        "\n",
        "A **Winsoriza√ß√£o** √© uma t√©cnica de tratamento de outliers que **limita valores extremos** sem remov√™-los completamente. Em vez de excluir outliers, substitu√≠mos os valores extremos pelos valores de percentis espec√≠ficos.\n",
        "\n",
        "**Como funciona:**\n",
        "- Define-se limites baseados em percentis (ex: 5¬∫ e 95¬∫ percentil)\n",
        "- Valores abaixo do limite inferior s√£o substitu√≠dos pelo valor do limite inferior\n",
        "- Valores acima do limite superior s√£o substitu√≠dos pelo valor do limite superior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmhrgtvXBUL8"
      },
      "source": [
        "| Vari√°vel                                 | Melhor m√©todo          | Resultado obtido |\n",
        "| :--------------------------------------- | :--------------------  | :-------------------------------------------------------------------------------------------------------- |\n",
        "| **precipitacao**                         | **Log(x + 1)**         | Assimetria (7.87 ‚Üí 2.59)                                                                                  |\n",
        "| **umidade_relativa_max**                 | **Winsoriza√ß√£o**       | Outliers (23 ‚Üí 0)                                                                                         |\n",
        "| **umidade_relativa_min**                 | **Winsoriza√ß√£o**       | Outliers (1155 ‚Üí 0)                                                                                       |\n",
        "| **umidade_especifica**                   | **Sqrt**               | Simetria (0.89 ‚Üí 0.16) / Outliers (6967 ‚Üí 2102)                                                           |\n",
        "| **radiacao_solar**                       | **Sem transforma√ß√£o**  |                                                                                                           |\n",
        "| **temperatura_min**                      | **Winsoriza√ß√£o**       | Outliers (5066 ‚Üí 0)                                                                                       |\n",
        "| **temperatura_max**                      | **Winsoriza√ß√£o**       | Outliers (5066 ‚Üí 0)                                                                                       |\n",
        "| **velocidade_vento**                     | **Log(x + 1)**         | Assimetria (1.23 ‚Üí 0.19) / Outliers (8723 ‚Üí 1128)                                                         |\n",
        "| **indice_queima**                        | **Winsoriza√ß√£o**       |                                                                                                           |\n",
        "| **umidade_combustivel_morto_100_horas**  | **Sqrt**               | Outliers (44 ‚Üí 9)                                                                                         |\n",
        "| **umidade_combustivel_morto_1000_horas** | **Sqrt**               | Outliers (373 ‚Üí 4)                                                                                        |\n",
        "| **componente_energia_lancada**           | **Sem transforma√ß√£o**  |                                                                                                           |\n",
        "| **evapotranspiracao_real**               | **Sqrt**               | Assimetria (0.71 ‚Üí -0.00) / Outliers (3292 ‚Üí 153)                                                         |\n",
        "| **evapotranspiracao_potencial**          | **Log(x + 1)**         | Outliers (679 ‚Üí 0)                                                                                        |\n",
        "| **deficit_pressao_vapor**                | **Log(x + 1)**         | Outliers (14758 ‚Üí 672)                                                                                    |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CYTi9RrGQd0x"
      },
      "outputs": [],
      "source": [
        "# @title Classe OutliersTreatment\n",
        "\n",
        "class OutliersTreatment(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.m_log_columns = [\n",
        "            \"precipitacao\",\n",
        "            \"velocidade_vento\",\n",
        "            \"evapotranspiracao_potencial\",\n",
        "            \"deficit_pressao_vapor\",\n",
        "        ]\n",
        "        self.m_sqrt_columns = [\n",
        "            \"umidade_especifica\",\n",
        "            \"umidade_combustivel_morto_100_horas\",\n",
        "            \"umidade_combustivel_morto_1000_horas\",\n",
        "            \"evapotranspiracao_real\",\n",
        "        ]\n",
        "        self.m_winsor_columns = [\n",
        "            \"umidade_relativa_max\",\n",
        "            \"umidade_relativa_min\",\n",
        "            \"temperatura_min\",\n",
        "            \"temperatura_max\",\n",
        "            \"indice_queima\",\n",
        "        ]\n",
        "        self.m_winsor_limits = (0.05, 0.05)\n",
        "\n",
        "    # Calcula par√¢metros necess√°rios para aplicar as transforma√ß√µes corretamente\n",
        "    def fit(self, dataframe, target=None):\n",
        "\n",
        "        # Garante que o usu√°rio esteja enviado um dataframe no formato correto\n",
        "        dataframe = dataframe if isinstance(dataframe, pd.DataFrame) else pd.DataFrame(dataframe)\n",
        "\n",
        "        # C√°lculo de offsets para garantir que n√£o haver√£o valores zerados ou negativos\n",
        "        # \"coerce\" convete valores inv√°lidos para NaN\n",
        "\n",
        "        self.m_log_offset = {}\n",
        "        for column in self.m_log_columns:\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                min_value = series.min()\n",
        "                self.m_log_offset[column] = (abs(min_value) + 1) if pd.notna(min_value) and min_value <= 0 else 1.0\n",
        "\n",
        "        self.m_sqrt_offset = {}\n",
        "        for column in self.m_sqrt_columns:\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                min_value = series.min()\n",
        "                self.m_sqrt_offset[column] = (abs(min_value) + 0.01) if pd.notna(min_value) and min_value < 0 else 0.0\n",
        "\n",
        "        # Garante que a winsoriza√ß√£o s√≥ seja feita com colunas que realmente est√£o no dataframe\n",
        "        actual_columns_to_winsor = [column for column in self.m_winsor_columns if column in dataframe.columns]\n",
        "        low_quantile, high_quantile = self.m_winsor_limits\n",
        "\n",
        "        if actual_columns_to_winsor:\n",
        "            # Converte cada coluna para num√©rico (coerces -> NaN) e calcula quantis por coluna\n",
        "            winsor_dataframe = dataframe[actual_columns_to_winsor].apply(pd.to_numeric, errors=\"coerce\")\n",
        "            self.m_low_quantile  = winsor_dataframe.quantile(low_quantile)\n",
        "            self.m_high_quantile = winsor_dataframe.quantile(1 - high_quantile)\n",
        "        else:\n",
        "            # garante atributos vazios para n√£o quebrar no transform()\n",
        "            self.m_low_quantile  = pd.Series(dtype=float)\n",
        "            self.m_high_quantile = pd.Series(dtype=float)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # Aplica as transforma√ß√µes\n",
        "    def transform(self, dataframe):\n",
        "\n",
        "        # Garante que o usu√°rio esteja enviado o dataframe correto\n",
        "        dataframe = dataframe.copy() if isinstance(dataframe, pd.DataFrame) else pd.DataFrame(dataframe).copy()\n",
        "\n",
        "        # LOG\n",
        "        for column, offset in self.m_log_offset.items():\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                dataframe[column] = np.log(series + offset)\n",
        "\n",
        "        # SQRT\n",
        "        for column, offset in self.m_sqrt_offset.items():\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                dataframe[column] = np.sqrt(series + offset)\n",
        "\n",
        "        # Winsoriza√ß√£o\n",
        "        for column in self.m_low_quantile.index:\n",
        "            if column in dataframe.columns:\n",
        "                series = pd.to_numeric(dataframe[column], errors=\"coerce\")\n",
        "                dataframe[column] = series.clip(lower=self.m_low_quantile[column], upper=self.m_high_quantile[column])\n",
        "\n",
        "        return dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BIYDz8rZ3j_"
      },
      "source": [
        "### 3. Normaliza√ß√£o dos dados\n",
        "\n",
        "S√£o utilizados para normalizar os dados num√©ricos\n",
        "- SimpleImputer -> Preenche NaN com a m√©dia da feature\n",
        "- MinMaxScaler -> Ajusta todos os valores para o intervalo entre 0 e 1\n",
        "\n",
        "No momento, n√£o est√£o sendo utilizadas features categ√≥ricas para treinar o modelo. Contudo, existe a implementa√ß√£o de uma normaliza√ß√£o para as mesmas\n",
        "- SimpleImputer -> Preenche NaN com a m√©dia da feature\n",
        "- OneHotEncoder -> Transforma vari√°veis categ√≥ricas em bin√°rias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "_HM_loh1QihZ"
      },
      "outputs": [],
      "source": [
        "# @title Classe DataNormalization\n",
        "\n",
        "'''\n",
        "categoric_cols = [season_column_name, region_column_name]\n",
        "\n",
        "def numeric_columns_selector(dataframe):\n",
        "    # Seleciona colunas num√©ricas, exceto as categ√≥ricas codificadas numericamente\n",
        "    num = dataframe.select_dtypes(include='number').columns.tolist()\n",
        "    return [column for column in num if column not in categoric_cols]\n",
        "\n",
        "categoric_columns_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
        "])\n",
        "'''\n",
        "\n",
        "numeric_columns_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ])\n",
        "\n",
        "DataNormalization = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numerical', numeric_columns_pipeline, make_column_selector(dtype_include='number')),\n",
        "        #('categoric', categoric_columns_pipeline, categoric_cols)\n",
        "    ],\n",
        "    remainder='passthrough'  # mant√©m quaisquer colunas n√£o listadas\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e8HI2VIZ3kA"
      },
      "source": [
        "### 4. Pipeline de pr√©-processamento\n",
        "\n",
        "Concentra 5 passos\n",
        "1. Cria√ß√£o de features\n",
        "2. Tratamento de outliers\n",
        "3. Elimina√ß√£o de features indesejadas no treinamento dos modelos\n",
        "4. Normaliza√ß√£o dos dados\n",
        "5. Sanitiza√ß√£o dos dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3mYGBgnZ3kA"
      },
      "source": [
        "Para que o modelo seja treinado de maneira correta, al√©m da coluna target, √© ideal que algumas outras fiquem de fora de seu escopo, s√£o elas:\n",
        "- Data\n",
        "- ID\n",
        "- Latitude\n",
        "- Longitude\n",
        "- Esta√ß√£o do ano\n",
        "- Regi√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Row-LFQnZ3kA"
      },
      "outputs": [],
      "source": [
        "# @title Classe ColumnDropper\n",
        "\n",
        "# Elimina colunas n√£o desej√°veis no treinamento do modelo\n",
        "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.columns = [data_column_name, id_column_name, latitude_column_name, longitude_column_name, season_column_name, region_column_name, indice_queima]\n",
        "    def fit(self, dataframe, target=None):\n",
        "        return self\n",
        "    def transform(self, dataframe):\n",
        "        return dataframe.drop(columns=self.columns, errors=\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XzKPN2PZ3kA"
      },
      "source": [
        "Fun√ß√£o simples que serve para garantir que os dados est√£o no formato esperado para que ocorra o treinamento dos modelos (numpy.ndarray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4A5dOlZkZ3kA"
      },
      "outputs": [],
      "source": [
        "# @title Fun√ß√£o sanitizer\n",
        "\n",
        "# Remove data e fire_id, al√©m de converter o dataframe para o formato esperado pelos classificadores\n",
        "def sanitizer(features):\n",
        "    # Transforma em numpy.ndarray\n",
        "    if isinstance(features, pd.DataFrame):\n",
        "        features = features.select_dtypes(include='number')\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kyUKC9duPwYA"
      },
      "outputs": [],
      "source": [
        "# @title Pipeline preprocess\n",
        "\n",
        "preprocess = Pipeline(steps=[\n",
        "    (\"features_creation\", FeaturesCreation()),\n",
        "    (\"outliers_treatment\", OutliersTreatment()),\n",
        "    (\"drop_unused_columns\", ColumnDropper()),\n",
        "    (\"data_normalization\", DataNormalization),\n",
        "    (\"sanitize\", FunctionTransformer(sanitizer, validate=False, feature_names_out='one-to-one'))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSxExLXsXrdc"
      },
      "source": [
        "### 5. Separa√ß√£o em treino/teste\n",
        "\n",
        "<u>**Time Series Cross Validation**</u>\n",
        "\n",
        "A Time Series Cross Validation √© uma t√©cnica especializada para validar modelos quando os dados possuem ordem cronol√≥gica. Diferente das t√©cnicas tradicionais, ela respeita a estrutura temporal dos dados.\n",
        "\n",
        "Foi implemetada uma fun√ß√£o personalizada para que dados referentes ao mesmo inc√™ndio permanecessem nos mesmos grupos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "4l1XXAgXQkt7"
      },
      "outputs": [],
      "source": [
        "# @title Fun√ß√£o group_time_series_cross_validation\n",
        "\n",
        "# Gera folds (train_idx, test_idx) respeitando ordem temporal por grupo, embargo em n√≠vel de grupo e exclus√£o m√∫tua treino/teste por grupo.\n",
        "def group_time_series_cross_validation():\n",
        "    dataframe = wildfires\n",
        "    time_column = data_column_name\n",
        "    group_column = id_column_name\n",
        "    folds_amount = 5\n",
        "    fold_groups_size = 1\n",
        "    gap_between_groups_amount = 0\n",
        "\n",
        "    # Ordena grupos pelo primeiro timestamp (data da primeira amostra do grupo)\n",
        "    first_time = (\n",
        "        dataframe[[group_column, time_column]]\n",
        "        .dropna(subset=[time_column])\n",
        "        .groupby(group_column)[time_column]\n",
        "        .min()\n",
        "        .sort_values()\n",
        "    )\n",
        "    ordered_groups = first_time.index.to_numpy()\n",
        "    ordered_groups_len = len(ordered_groups)\n",
        "\n",
        "    groups_amount_by_step = fold_groups_size\n",
        "\n",
        "    min_train_groups = max(1, fold_groups_size) # pelo menos 1\n",
        "\n",
        "    # √Çncora: √∫ltimo grupo incluso no treino\n",
        "    # Precisamos garantir espa√ßo para gap + teste √† frente\n",
        "    max_anchor = ordered_groups_len - gap_between_groups_amount - fold_groups_size\n",
        "    if max_anchor <= min_train_groups:\n",
        "        return  # n√£o h√° splits poss√≠veis\n",
        "\n",
        "    splits = 0\n",
        "    anchor = min_train_groups\n",
        "    while anchor <= max_anchor and splits < folds_amount:\n",
        "        train_groups = ordered_groups[:anchor]\n",
        "\n",
        "        test_start = anchor + gap_between_groups_amount\n",
        "        test_end = test_start + fold_groups_size\n",
        "        test_groups = ordered_groups[test_start:test_end]\n",
        "\n",
        "        train_idx = dataframe.index[dataframe[group_column].isin(train_groups)].to_numpy()\n",
        "        test_idx  = dataframe.index[dataframe[group_column].isin(test_groups)].to_numpy()\n",
        "\n",
        "        if train_idx.size and test_idx.size:\n",
        "            yield (train_idx, test_idx) # Gera√ß√£o sobre demanda (lazy evaluation)\n",
        "            splits += 1\n",
        "\n",
        "        anchor += groups_amount_by_step\n",
        "\n",
        "cross_validation = cross_validation_splits = list(group_time_series_cross_validation())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EuWr-2wZ3kB"
      },
      "source": [
        "### 6. Balanceamento dos dados\n",
        "\n",
        "Ap√≥s rodar um algoritmo que contava a quantidade de amostras de cada classe e tamb√©m calculava a Raz√£o de Desbalanceamento (IR), obtivemos:\n",
        "- Classe 0 (n√£o-inc√™ndio): **2025** amostras acumuladas entre todas as folds (90%)\n",
        "- Classe 1 (inc√™ndio): **225** amostras acumuladas entre todas as folds (10%)\n",
        "- Raz√£o de desbalanceamento (IR) acumulada: **9.00x**\n",
        "\n",
        "**Observa√ß√£o**: o dataset possui mais de 300.000 linhas, mas apenas 2.500 grupos distintos (separados por inc√™ndio)\n",
        "\n",
        "O dataset apresenta uma raz√£o de desbalanceamento leve (IR < 10), o que n√£o levanta a necessidade de utiliza√ß√£o de algoritmos robustos para balanceamento.\n",
        "\n",
        "Com essa informa√ß√£o em mente, foram feitos testes em alguns modelos que aceitavam como par√¢metro o \"peso\" dos dados (class_weight = 'balanced') e os resultados foram esses:\n",
        "\n",
        "**LogisticRegression** ‚úÖ\n",
        "| M√©trica   | Antes | Depois    | Diferen√ßa |\n",
        "| --------- | ----- | --------- | --------- |\n",
        "| Accuracy  | 0.921 | **0.932** | üîº +0.011 |\n",
        "| Precision | 0.529 | **0.765** | üîº +0.236 |\n",
        "| Recall    | 0.293 | **0.787** | üîº +0.494 |\n",
        "| F1-score  | 0.335 | **0.715** | üîº +0.380 |\n",
        "| ROC AUC   | 0.975 | **0.979** | üîº +0.004 |\n",
        "\n",
        "**DecisionTreeClassifier** ‚úÖ\n",
        "| M√©trica   | Antes | Depois    | Diferen√ßa |\n",
        "| --------- | ----- | --------- | --------- |\n",
        "| Accuracy  | 0.909 | **0.940** | üîº +0.031 |\n",
        "| Precision | 0.506 | **0.826** | üîº +0.320 |\n",
        "| Recall    | 0.413 | **0.680** | üîº +0.267 |\n",
        "| F1-score  | 0.391 | **0.662** | üîº +0.271 |\n",
        "| ROC AUC   | 0.727 | **0.824** | üîº +0.097 |\n",
        "\n",
        "\n",
        "**RandomForestClassifier** ‚úÖ\n",
        "| M√©trica   | Antes | Depois    | Diferen√ßa       |\n",
        "| --------- | ----- | --------- | --------------- |\n",
        "| Accuracy  | 0.925 | **0.933** | üîº +0.008       |\n",
        "| Precision | 0.859 | **0.876** | üîº +0.017       |\n",
        "| Recall    | 0.507 | **0.560** | üîº +0.053       |\n",
        "| F1-score  | 0.498 | **0.566** | üîº +0.068       |\n",
        "| ROC AUC   | 0.947 | 0.947     | ‚ö™ sem varia√ß√£o |\n",
        "\n",
        "**XGBoost (scale_pos_weight=9.0)** üü®\n",
        "| M√©trica   | Antes     | Depois    | Diferen√ßa |\n",
        "| --------- | --------- | --------- | --------- |\n",
        "| Accuracy  | **0.935** | 0.927     | üîª -0.008 |\n",
        "| Precision | **0.830** | 0.797     | üîª -0.033 |\n",
        "| Recall    | 0.653     | **0.693** | üîº +0.040 |\n",
        "| F1-score  | 0.635     | **0.638** | üîº +0.003 |\n",
        "| ROC AUC   | **0.950** | 0.946     | üîª -0.004 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Zoqs2u5ZZ3kB"
      },
      "outputs": [],
      "source": [
        "# @title Classe BalancingCount\n",
        "\n",
        "# Classe que balancea os dados\n",
        "class BalancingCount(BaseEstimator, TransformerMixin):\n",
        "    # Vari√°veis de classe (compartilhadas entre todas as inst√¢ncias)\n",
        "    total_counts = None\n",
        "    total_calls = 0\n",
        "\n",
        "    def fit(self, dataframe, target=None):\n",
        "        if target is None:\n",
        "            raise ValueError(\"O target √© obrigat√≥rio para verificar o balanceamento.\")\n",
        "\n",
        "        # Conta as ocorr√™ncias por classe neste fold\n",
        "        counts = pd.Series(target).value_counts().sort_index()\n",
        "\n",
        "        # Atualiza contagem total global\n",
        "        if BalancingCount.total_counts is None:\n",
        "            BalancingCount.total_counts = counts.copy()\n",
        "        else:\n",
        "            # soma os valores por classe\n",
        "            BalancingCount.total_counts = BalancingCount.total_counts.add(counts, fill_value=0)\n",
        "\n",
        "        BalancingCount.total_calls += 1\n",
        "\n",
        "        # --- Exibi√ß√£o do fold atual ---\n",
        "        print(f\"\\nüìò Fold {BalancingCount.total_calls}\")\n",
        "        print(\"üìä Contagem de classes (este fold):\")\n",
        "        for classes, count in counts.items():\n",
        "            print(f\"  Classe {classes}: {count} amostras\")\n",
        "\n",
        "        ratio = counts.max() / counts.min() if len(counts) > 1 else 1.0\n",
        "        print(f\"‚öñÔ∏è  Raz√£o de desbalanceamento (este fold): {ratio:.2f}x\")\n",
        "\n",
        "        # --- Exibi√ß√£o acumulada ---\n",
        "        if BalancingCount.total_calls == 1:\n",
        "            print(\"\\nüîÑ Iniciando contagem global...\")\n",
        "        else:\n",
        "            total_ratio = BalancingCount.total_counts.max() / BalancingCount.total_counts.min()\n",
        "            print(\"\\nüìà Contagem acumulada at√© agora:\")\n",
        "            for classes, total in BalancingCount.total_counts.items():\n",
        "                print(f\"  Classe {int(classes)}: {int(total)} amostras acumuladas\")\n",
        "            print(f\"‚öñÔ∏è  Raz√£o de desbalanceamento acumulada: {total_ratio:.2f}x\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, dataframe):\n",
        "        return dataframe\n",
        "\n",
        "    @classmethod\n",
        "    def reset(cls):\n",
        "        \"\"\"Reseta contadores globais (para novo experimento).\"\"\"\n",
        "        cls.total_counts = None\n",
        "        cls.total_calls = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry8Mmj45Z3kC"
      },
      "source": [
        "### 7. Treinamento dos modelos\n",
        "\n",
        "Os modelos treinados foram\n",
        "- Dummy (mais frequente)\n",
        "- Regress√£o Log√≠stica\n",
        "- √Årvore de Decis√£o\n",
        "- Random Forest\n",
        "- Naive Bayes\n",
        "- KNN\n",
        "- Gradient Boosting\n",
        "- AdaBoost\n",
        "- HistGradientBoosting\n",
        "- RidgeClassifier\n",
        "- XGBoost\n",
        "- CatBoost "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m55_3mwUZ3kC"
      },
      "source": [
        "<u>**M√©tricas para avalia√ß√£o dos modelos**</u>\n",
        "\n",
        "| **M√©trica**                | **Descri√ß√£o**                                                                               | **Interpreta√ß√£o ideal**                                                                  |\n",
        "| -------------------------- | ------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- |\n",
        "| **Accuracy**               | Propor√ß√£o de acertos totais (tanto positivos quanto negativos).                             | Boa para classes balanceadas, mas pode mascarar desempenho ruim em classes minorit√°rias. |\n",
        "| **Precision**              | Entre as previs√µes positivas, quantas realmente eram positivas.                             | Alta precis√£o = poucos falsos positivos.                                                 |\n",
        "| **Recall (Sensibilidade)** | Entre os casos realmente positivos, quantos foram identificados corretamente.               | Alto recall = poucos falsos negativos.                                                   |\n",
        "| **F1-score**               | M√©dia harm√¥nica entre precis√£o e recall, equilibrando ambos.                                | Ideal quando h√° desbalanceamento de classes.                                             |\n",
        "| **ROC AUC**                | Mede a capacidade global do modelo em separar as classes (0.5 = aleat√≥rio; 1.0 = perfeito). | Pr√≥ximo de 1 indica boa separabilidade.                                                  |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TYMCJN0ZZ3kC"
      },
      "outputs": [],
      "source": [
        "# @title Escolha dos modelos e das m√©tricas\n",
        "\n",
        "modelos = {\n",
        "    \"Dummy (mais frequente)\": DummyClassifier(strategy=\"most_frequent\"), # Baseline simples\n",
        "\n",
        "    # Sem balanceamento\n",
        "    # \"Regress√£o Log√≠stica\": LogisticRegression(C=0.5, penalty='l2', solver='liblinear', max_iter=2000), # Regulariza√ß√£o L2 leve\n",
        "    # \"√Årvore de Decis√£o\": DecisionTreeClassifier(max_depth=8, min_samples_split=4, min_samples_leaf=2, random_state=42), # Controle de profundidade e tamanho da folha\n",
        "    # \"Random Forest\": RandomForestClassifier(n_estimators=150, max_depth=10, min_samples_split=5,random_state=42, n_jobs=-1), # Mais √°rvores e profundidade moderada\n",
        "\n",
        "    # Com balanceamento\n",
        "    \"Regress√£o Log√≠stica\": LogisticRegression(C=0.5, penalty='l2', solver='liblinear', max_iter=2000, class_weight = 'balanced'), # Regulariza√ß√£o L2 leve\n",
        "    \"√Årvore de Decis√£o\": DecisionTreeClassifier(max_depth=8, min_samples_split=4, min_samples_leaf=2, random_state=42, class_weight = 'balanced'), # Controle de profundidade e tamanho da folha\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=150, max_depth=10, min_samples_split=5,random_state=42, n_jobs=-1, class_weight = 'balanced'), # Mais √°rvores e profundidade moderada\n",
        "\n",
        "    \"Naive Bayes\": GaussianNB(var_smoothing=1e-8), # Suaviza√ß√£o leve (mais est√°vel)\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=7, weights='distance'), # Mais vizinhos e dist√¢ncia ponderada\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42), # Par√¢metros leves conforme aula\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42), # Taxa de aprendizado menor\n",
        "    \"HistGradientBoosting\": HistGradientBoostingClassifier(max_iter=150, learning_rate=0.05, max_depth=5, random_state=42), # Mais itera√ß√µes e taxa menor\n",
        "    \"RidgeClassifier\": RidgeClassifier(alpha=1.0), # Regulariza√ß√£o leve\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='logloss', n_estimators=150, learning_rate=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8, random_state=42), #  Par√¢metros t√≠picos de equil√≠brio (aula 15 parte 4)\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=150, learning_rate=0.05, depth=5,verbose=0, random_state=42), # Taxa de aprendizado reduzida e itera√ß√µes extras\n",
        "}\n",
        "\n",
        "# M√©tricas de avalia√ß√£o\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': make_scorer(precision_score, zero_division=0),\n",
        "    'recall': make_scorer(recall_score, zero_division=0),\n",
        "    'f1': make_scorer(f1_score, zero_division=0),\n",
        "    'roc_auc': 'roc_auc'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "urmjqpSaZ3kC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per√≠odo de dias:  30\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regress√£o Log√≠stica</td>\n",
              "      <td>0.929333</td>\n",
              "      <td>0.761782</td>\n",
              "      <td>0.773333</td>\n",
              "      <td>0.696126</td>\n",
              "      <td>0.973432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.546667</td>\n",
              "      <td>0.579238</td>\n",
              "      <td>0.943210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.905333</td>\n",
              "      <td>0.716920</td>\n",
              "      <td>0.653333</td>\n",
              "      <td>0.578059</td>\n",
              "      <td>0.952593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>0.893750</td>\n",
              "      <td>0.506667</td>\n",
              "      <td>0.537889</td>\n",
              "      <td>0.947506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√Årvore de Decis√£o</td>\n",
              "      <td>0.914667</td>\n",
              "      <td>0.770635</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.535132</td>\n",
              "      <td>0.723358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.527165</td>\n",
              "      <td>0.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.922667</td>\n",
              "      <td>0.888235</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.497632</td>\n",
              "      <td>0.947062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.922667</td>\n",
              "      <td>0.671569</td>\n",
              "      <td>0.493333</td>\n",
              "      <td>0.491209</td>\n",
              "      <td>0.963457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.901333</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.426667</td>\n",
              "      <td>0.439888</td>\n",
              "      <td>0.797531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>0.496774</td>\n",
              "      <td>0.373333</td>\n",
              "      <td>0.357101</td>\n",
              "      <td>0.988444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.886667</td>\n",
              "      <td>0.563235</td>\n",
              "      <td>0.453333</td>\n",
              "      <td>0.323207</td>\n",
              "      <td>0.906765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy (mais frequente)</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Modelo  Accuracy  Precision    Recall  F1-score   ROC AUC\n",
              "1      Regress√£o Log√≠stica  0.929333   0.761782  0.773333  0.696126  0.973432\n",
              "10                 XGBoost  0.928000   0.885714  0.546667  0.579238  0.943210\n",
              "4              Naive Bayes  0.905333   0.716920  0.653333  0.578059  0.952593\n",
              "3            Random Forest  0.928000   0.893750  0.506667  0.537889  0.947506\n",
              "2        √Årvore de Decis√£o  0.914667   0.770635  0.480000  0.535132  0.723358\n",
              "5                      KNN  0.928000   0.900000  0.480000  0.527165  0.873728\n",
              "11                CatBoost  0.922667   0.888235  0.480000  0.497632  0.947062\n",
              "8     HistGradientBoosting  0.922667   0.671569  0.493333  0.491209  0.963457\n",
              "6        Gradient Boosting  0.901333   0.695652  0.426667  0.439888  0.797531\n",
              "9          RidgeClassifier  0.916000   0.496774  0.373333  0.357101  0.988444\n",
              "7                 AdaBoost  0.886667   0.563235  0.453333  0.323207  0.906765\n",
              "0   Dummy (mais frequente)  0.900000   0.000000  0.000000  0.000000  0.500000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per√≠odo de dias:  60\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regress√£o Log√≠stica</td>\n",
              "      <td>0.925333</td>\n",
              "      <td>0.758333</td>\n",
              "      <td>0.746667</td>\n",
              "      <td>0.681081</td>\n",
              "      <td>0.974222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.908000</td>\n",
              "      <td>0.722832</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.586061</td>\n",
              "      <td>0.949333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.926667</td>\n",
              "      <td>0.896552</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.519975</td>\n",
              "      <td>0.874469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.487167</td>\n",
              "      <td>0.939802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.921333</td>\n",
              "      <td>0.659664</td>\n",
              "      <td>0.493333</td>\n",
              "      <td>0.486462</td>\n",
              "      <td>0.957975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>0.857466</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.440376</td>\n",
              "      <td>0.944099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.917333</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.436290</td>\n",
              "      <td>0.945975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√Årvore de Decis√£o</td>\n",
              "      <td>0.913333</td>\n",
              "      <td>0.664286</td>\n",
              "      <td>0.386667</td>\n",
              "      <td>0.428165</td>\n",
              "      <td>0.679259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.890667</td>\n",
              "      <td>0.762637</td>\n",
              "      <td>0.493333</td>\n",
              "      <td>0.391895</td>\n",
              "      <td>0.895802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.503448</td>\n",
              "      <td>0.386667</td>\n",
              "      <td>0.380574</td>\n",
              "      <td>0.989827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.908000</td>\n",
              "      <td>0.822222</td>\n",
              "      <td>0.373333</td>\n",
              "      <td>0.374529</td>\n",
              "      <td>0.827802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy (mais frequente)</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Modelo  Accuracy  Precision    Recall  F1-score   ROC AUC\n",
              "1      Regress√£o Log√≠stica  0.925333   0.758333  0.746667  0.681081  0.974222\n",
              "4              Naive Bayes  0.908000   0.722832  0.666667  0.586061  0.949333\n",
              "5                      KNN  0.926667   0.896552  0.466667  0.519975  0.874469\n",
              "10                 XGBoost  0.920000   0.885714  0.466667  0.487167  0.939802\n",
              "8     HistGradientBoosting  0.921333   0.659664  0.493333  0.486462  0.957975\n",
              "3            Random Forest  0.916000   0.857466  0.440000  0.440376  0.944099\n",
              "11                CatBoost  0.917333   0.685714  0.440000  0.436290  0.945975\n",
              "2        √Årvore de Decis√£o  0.913333   0.664286  0.386667  0.428165  0.679259\n",
              "7                 AdaBoost  0.890667   0.762637  0.493333  0.391895  0.895802\n",
              "9          RidgeClassifier  0.920000   0.503448  0.386667  0.380574  0.989827\n",
              "6        Gradient Boosting  0.908000   0.822222  0.373333  0.374529  0.827802\n",
              "0   Dummy (mais frequente)  0.900000   0.000000  0.000000  0.000000  0.500000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per√≠odo de dias:  90\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regress√£o Log√≠stica</td>\n",
              "      <td>0.929333</td>\n",
              "      <td>0.758210</td>\n",
              "      <td>0.773333</td>\n",
              "      <td>0.698816</td>\n",
              "      <td>0.978173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√Årvore de Decis√£o</td>\n",
              "      <td>0.945333</td>\n",
              "      <td>0.864935</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>0.661328</td>\n",
              "      <td>0.797086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.937333</td>\n",
              "      <td>0.836607</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.657496</td>\n",
              "      <td>0.952296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.909333</td>\n",
              "      <td>0.727697</td>\n",
              "      <td>0.653333</td>\n",
              "      <td>0.573273</td>\n",
              "      <td>0.955605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>0.855615</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.561345</td>\n",
              "      <td>0.955111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.910667</td>\n",
              "      <td>0.773950</td>\n",
              "      <td>0.626667</td>\n",
              "      <td>0.553794</td>\n",
              "      <td>0.895753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.925333</td>\n",
              "      <td>0.628235</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.535890</td>\n",
              "      <td>0.968346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.925333</td>\n",
              "      <td>0.896552</td>\n",
              "      <td>0.453333</td>\n",
              "      <td>0.508117</td>\n",
              "      <td>0.858914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.912000</td>\n",
              "      <td>0.791684</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.504368</td>\n",
              "      <td>0.947852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>0.812941</td>\n",
              "      <td>0.426667</td>\n",
              "      <td>0.482860</td>\n",
              "      <td>0.832346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.922667</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.357059</td>\n",
              "      <td>0.993284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy (mais frequente)</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Modelo  Accuracy  Precision    Recall  F1-score   ROC AUC\n",
              "1      Regress√£o Log√≠stica  0.929333   0.758210  0.773333  0.698816  0.978173\n",
              "2        √Årvore de Decis√£o  0.945333   0.864935  0.613333  0.661328  0.797086\n",
              "10                 XGBoost  0.937333   0.836607  0.680000  0.657496  0.952296\n",
              "4              Naive Bayes  0.909333   0.727697  0.653333  0.573273  0.955605\n",
              "3            Random Forest  0.928000   0.855615  0.560000  0.561345  0.955111\n",
              "7                 AdaBoost  0.910667   0.773950  0.626667  0.553794  0.895753\n",
              "8     HistGradientBoosting  0.925333   0.628235  0.586667  0.535890  0.968346\n",
              "5                      KNN  0.925333   0.896552  0.453333  0.508117  0.858914\n",
              "11                CatBoost  0.912000   0.791684  0.560000  0.504368  0.947852\n",
              "6        Gradient Boosting  0.924000   0.812941  0.426667  0.482860  0.832346\n",
              "9          RidgeClassifier  0.922667   0.520000  0.360000  0.357059  0.993284\n",
              "0   Dummy (mais frequente)  0.900000   0.000000  0.000000  0.000000  0.500000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per√≠odo de dias:  120\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regress√£o Log√≠stica</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>0.759524</td>\n",
              "      <td>0.773333</td>\n",
              "      <td>0.697876</td>\n",
              "      <td>0.975802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.930667</td>\n",
              "      <td>0.841118</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600591</td>\n",
              "      <td>0.951901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.929333</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.563083</td>\n",
              "      <td>0.900296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.905333</td>\n",
              "      <td>0.725673</td>\n",
              "      <td>0.626667</td>\n",
              "      <td>0.529510</td>\n",
              "      <td>0.951951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.926667</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.526619</td>\n",
              "      <td>0.850568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√Årvore de Decis√£o</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>0.614652</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.480423</td>\n",
              "      <td>0.724790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.917333</td>\n",
              "      <td>0.809586</td>\n",
              "      <td>0.453333</td>\n",
              "      <td>0.477103</td>\n",
              "      <td>0.821383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.912000</td>\n",
              "      <td>0.800893</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.465130</td>\n",
              "      <td>0.926321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.922667</td>\n",
              "      <td>0.861480</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.461704</td>\n",
              "      <td>0.948642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>0.655556</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.439719</td>\n",
              "      <td>0.968444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.360905</td>\n",
              "      <td>0.991901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy (mais frequente)</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Modelo  Accuracy  Precision    Recall  F1-score   ROC AUC\n",
              "1      Regress√£o Log√≠stica  0.932000   0.759524  0.773333  0.697876  0.975802\n",
              "10                 XGBoost  0.930667   0.841118  0.600000  0.600591  0.951901\n",
              "7                 AdaBoost  0.929333   0.830769  0.586667  0.563083  0.900296\n",
              "4              Naive Bayes  0.905333   0.725673  0.626667  0.529510  0.951951\n",
              "5                      KNN  0.926667   0.892857  0.466667  0.526619  0.850568\n",
              "2        √Årvore de Decis√£o  0.928000   0.614652  0.466667  0.480423  0.724790\n",
              "6        Gradient Boosting  0.917333   0.809586  0.453333  0.477103  0.821383\n",
              "11                CatBoost  0.912000   0.800893  0.520000  0.465130  0.926321\n",
              "3            Random Forest  0.922667   0.861480  0.480000  0.461704  0.948642\n",
              "8     HistGradientBoosting  0.924000   0.655556  0.466667  0.439719  0.968444\n",
              "9          RidgeClassifier  0.924000   0.525000  0.360000  0.360905  0.991901\n",
              "0   Dummy (mais frequente)  0.900000   0.000000  0.000000  0.000000  0.500000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per√≠odo de dias:  150\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regress√£o Log√≠stica</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.695119</td>\n",
              "      <td>0.973037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.934667</td>\n",
              "      <td>0.652941</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.605810</td>\n",
              "      <td>0.971309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.930667</td>\n",
              "      <td>0.869048</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.603071</td>\n",
              "      <td>0.950123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.921333</td>\n",
              "      <td>0.822078</td>\n",
              "      <td>0.573333</td>\n",
              "      <td>0.543507</td>\n",
              "      <td>0.895802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.922667</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.426667</td>\n",
              "      <td>0.488787</td>\n",
              "      <td>0.843852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.902667</td>\n",
              "      <td>0.520854</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.488443</td>\n",
              "      <td>0.949185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>0.841231</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.462623</td>\n",
              "      <td>0.767309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√Årvore de Decis√£o</td>\n",
              "      <td>0.921333</td>\n",
              "      <td>0.678261</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.457907</td>\n",
              "      <td>0.689630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.918667</td>\n",
              "      <td>0.888235</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.454508</td>\n",
              "      <td>0.933580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.908000</td>\n",
              "      <td>0.625714</td>\n",
              "      <td>0.426667</td>\n",
              "      <td>0.352059</td>\n",
              "      <td>0.945086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.293333</td>\n",
              "      <td>0.297059</td>\n",
              "      <td>0.988346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy (mais frequente)</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Modelo  Accuracy  Precision    Recall  F1-score   ROC AUC\n",
              "1      Regress√£o Log√≠stica  0.933333   0.770000  0.760000  0.695119  0.973037\n",
              "8     HistGradientBoosting  0.934667   0.652941  0.640000  0.605810  0.971309\n",
              "10                 XGBoost  0.930667   0.869048  0.586667  0.603071  0.950123\n",
              "7                 AdaBoost  0.921333   0.822078  0.573333  0.543507  0.895802\n",
              "5                      KNN  0.922667   0.892857  0.426667  0.488787  0.843852\n",
              "4              Naive Bayes  0.902667   0.520854  0.586667  0.488443  0.949185\n",
              "6        Gradient Boosting  0.916000   0.841231  0.400000  0.462623  0.767309\n",
              "2        √Årvore de Decis√£o  0.921333   0.678261  0.400000  0.457907  0.689630\n",
              "3            Random Forest  0.918667   0.888235  0.440000  0.454508  0.933580\n",
              "11                CatBoost  0.908000   0.625714  0.426667  0.352059  0.945086\n",
              "9          RidgeClassifier  0.916000   0.520000  0.293333  0.297059  0.988346\n",
              "0   Dummy (mais frequente)  0.900000   0.000000  0.000000  0.000000  0.500000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per√≠odo de dias:  180\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regress√£o Log√≠stica</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.695119</td>\n",
              "      <td>0.973037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.934667</td>\n",
              "      <td>0.652941</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.605810</td>\n",
              "      <td>0.971309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.930667</td>\n",
              "      <td>0.869048</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.603071</td>\n",
              "      <td>0.950123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.921333</td>\n",
              "      <td>0.822078</td>\n",
              "      <td>0.573333</td>\n",
              "      <td>0.543507</td>\n",
              "      <td>0.895802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.922667</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.426667</td>\n",
              "      <td>0.488787</td>\n",
              "      <td>0.843852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.902667</td>\n",
              "      <td>0.520854</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.488443</td>\n",
              "      <td>0.949185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>0.841231</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.462623</td>\n",
              "      <td>0.767309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√Årvore de Decis√£o</td>\n",
              "      <td>0.921333</td>\n",
              "      <td>0.678261</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.457907</td>\n",
              "      <td>0.689630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.918667</td>\n",
              "      <td>0.888235</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.454508</td>\n",
              "      <td>0.933580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.908000</td>\n",
              "      <td>0.625714</td>\n",
              "      <td>0.426667</td>\n",
              "      <td>0.352059</td>\n",
              "      <td>0.945086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.293333</td>\n",
              "      <td>0.297059</td>\n",
              "      <td>0.988346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy (mais frequente)</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Modelo  Accuracy  Precision    Recall  F1-score   ROC AUC\n",
              "1      Regress√£o Log√≠stica  0.933333   0.770000  0.760000  0.695119  0.973037\n",
              "8     HistGradientBoosting  0.934667   0.652941  0.640000  0.605810  0.971309\n",
              "10                 XGBoost  0.930667   0.869048  0.586667  0.603071  0.950123\n",
              "7                 AdaBoost  0.921333   0.822078  0.573333  0.543507  0.895802\n",
              "5                      KNN  0.922667   0.892857  0.426667  0.488787  0.843852\n",
              "4              Naive Bayes  0.902667   0.520854  0.586667  0.488443  0.949185\n",
              "6        Gradient Boosting  0.916000   0.841231  0.400000  0.462623  0.767309\n",
              "2        √Årvore de Decis√£o  0.921333   0.678261  0.400000  0.457907  0.689630\n",
              "3            Random Forest  0.918667   0.888235  0.440000  0.454508  0.933580\n",
              "11                CatBoost  0.908000   0.625714  0.426667  0.352059  0.945086\n",
              "9          RidgeClassifier  0.916000   0.520000  0.293333  0.297059  0.988346\n",
              "0   Dummy (mais frequente)  0.900000   0.000000  0.000000  0.000000  0.500000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per√≠odo de dias:  210\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regress√£o Log√≠stica</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.695119</td>\n",
              "      <td>0.973037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.934667</td>\n",
              "      <td>0.652941</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.605810</td>\n",
              "      <td>0.971309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.930667</td>\n",
              "      <td>0.869048</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.603071</td>\n",
              "      <td>0.950123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.921333</td>\n",
              "      <td>0.822078</td>\n",
              "      <td>0.573333</td>\n",
              "      <td>0.543507</td>\n",
              "      <td>0.895802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.922667</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.426667</td>\n",
              "      <td>0.488787</td>\n",
              "      <td>0.843852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.902667</td>\n",
              "      <td>0.520854</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.488443</td>\n",
              "      <td>0.949185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>0.841231</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.462623</td>\n",
              "      <td>0.767309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√Årvore de Decis√£o</td>\n",
              "      <td>0.921333</td>\n",
              "      <td>0.678261</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.457907</td>\n",
              "      <td>0.689630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.918667</td>\n",
              "      <td>0.888235</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.454508</td>\n",
              "      <td>0.933580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.908000</td>\n",
              "      <td>0.625714</td>\n",
              "      <td>0.426667</td>\n",
              "      <td>0.352059</td>\n",
              "      <td>0.945086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.293333</td>\n",
              "      <td>0.297059</td>\n",
              "      <td>0.988346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy (mais frequente)</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Modelo  Accuracy  Precision    Recall  F1-score   ROC AUC\n",
              "1      Regress√£o Log√≠stica  0.933333   0.770000  0.760000  0.695119  0.973037\n",
              "8     HistGradientBoosting  0.934667   0.652941  0.640000  0.605810  0.971309\n",
              "10                 XGBoost  0.930667   0.869048  0.586667  0.603071  0.950123\n",
              "7                 AdaBoost  0.921333   0.822078  0.573333  0.543507  0.895802\n",
              "5                      KNN  0.922667   0.892857  0.426667  0.488787  0.843852\n",
              "4              Naive Bayes  0.902667   0.520854  0.586667  0.488443  0.949185\n",
              "6        Gradient Boosting  0.916000   0.841231  0.400000  0.462623  0.767309\n",
              "2        √Årvore de Decis√£o  0.921333   0.678261  0.400000  0.457907  0.689630\n",
              "3            Random Forest  0.918667   0.888235  0.440000  0.454508  0.933580\n",
              "11                CatBoost  0.908000   0.625714  0.426667  0.352059  0.945086\n",
              "9          RidgeClassifier  0.916000   0.520000  0.293333  0.297059  0.988346\n",
              "0   Dummy (mais frequente)  0.900000   0.000000  0.000000  0.000000  0.500000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title Algoritmo de treinamento\n",
        "\n",
        "features = wildfires.drop(columns=target_column_name)\n",
        "target = wildfires[target_column_name].astype(int)\n",
        "\n",
        "periodos_testes = [30, 60, 90, 120, 150, 180, 210]\n",
        "\n",
        "resultados_gerais = []\n",
        "\n",
        "for periodo in periodos_testes:\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    window_days = periodo\n",
        "    print(\"Per√≠odo de dias: \", periodo)\n",
        "\n",
        "    for nome, modelo in modelos.items():\n",
        "        # print(f\"Treinando modelo: {nome}...\")\n",
        "        # BalancingCount.reset()\n",
        "\n",
        "        try:\n",
        "            pipeline = Pipeline([\n",
        "                (\"preprocess\", preprocess),\n",
        "                (\"nan_shield\", SimpleImputer(strategy=\"constant\", fill_value=0.0)), # Blindagem contra NaN\n",
        "                # (\"balancing\", BalancingCount()),\n",
        "                (\"classificator\", modelo)\n",
        "            ])\n",
        "\n",
        "            scores = cross_validate(\n",
        "                pipeline,\n",
        "                features,\n",
        "                target,\n",
        "                cv=cross_validation,\n",
        "                scoring=scoring,\n",
        "                n_jobs=1\n",
        "            )\n",
        "\n",
        "            resultados.append({\n",
        "                \"Modelo\": nome,\n",
        "                \"Accuracy\": np.mean(scores['test_accuracy']),\n",
        "                \"Precision\": np.mean(scores['test_precision']),\n",
        "                \"Recall\": np.mean(scores['test_recall']),\n",
        "                \"F1-score\": np.mean(scores['test_f1']),\n",
        "                \"ROC AUC\": np.mean(scores['test_roc_auc']),\n",
        "            })\n",
        "\n",
        "            resultados_gerais.append({\n",
        "                \"Modelo\": nome,\n",
        "                \"F1-score\": np.mean(scores['test_f1']),\n",
        "                \"Tempo\": periodo\n",
        "            })\n",
        "\n",
        "            # print(f\" Modelo {nome} treinado com sucesso.\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            pass\n",
        "            # print(f\" Erro ao rodar o modelo {nome}: {e}\\n\")\n",
        "\n",
        "    # Mostra os resultados por per√≠odo\n",
        "    df_resultados = pd.DataFrame(resultados).sort_values(\"F1-score\", ascending=False)\n",
        "    display(df_resultados)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4sK2Cx9YZ3kD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Modelo: Dummy (mais frequente) ====\n",
            "1¬∫ lugar | Tempo:  30 dias | F1-score: 0.0000\n",
            "2¬∫ lugar | Tempo:  60 dias | F1-score: 0.0000\n",
            "3¬∫ lugar | Tempo:  90 dias | F1-score: 0.0000\n",
            "4¬∫ lugar | Tempo: 120 dias | F1-score: 0.0000\n",
            "5¬∫ lugar | Tempo: 150 dias | F1-score: 0.0000\n",
            "6¬∫ lugar | Tempo: 180 dias | F1-score: 0.0000\n",
            "7¬∫ lugar | Tempo: 210 dias | F1-score: 0.0000\n",
            "\n",
            "==== Modelo: Regress√£o Log√≠stica ====\n",
            "1¬∫ lugar | Tempo:  90 dias | F1-score: 0.6988\n",
            "2¬∫ lugar | Tempo: 120 dias | F1-score: 0.6979\n",
            "3¬∫ lugar | Tempo:  30 dias | F1-score: 0.6961\n",
            "4¬∫ lugar | Tempo: 150 dias | F1-score: 0.6951\n",
            "5¬∫ lugar | Tempo: 180 dias | F1-score: 0.6951\n",
            "6¬∫ lugar | Tempo: 210 dias | F1-score: 0.6951\n",
            "7¬∫ lugar | Tempo:  60 dias | F1-score: 0.6811\n",
            "\n",
            "==== Modelo: √Årvore de Decis√£o ====\n",
            "1¬∫ lugar | Tempo:  90 dias | F1-score: 0.6613\n",
            "2¬∫ lugar | Tempo:  30 dias | F1-score: 0.5351\n",
            "3¬∫ lugar | Tempo: 120 dias | F1-score: 0.4804\n",
            "4¬∫ lugar | Tempo: 150 dias | F1-score: 0.4579\n",
            "5¬∫ lugar | Tempo: 180 dias | F1-score: 0.4579\n",
            "6¬∫ lugar | Tempo: 210 dias | F1-score: 0.4579\n",
            "7¬∫ lugar | Tempo:  60 dias | F1-score: 0.4282\n",
            "\n",
            "==== Modelo: Random Forest ====\n",
            "1¬∫ lugar | Tempo:  90 dias | F1-score: 0.5613\n",
            "2¬∫ lugar | Tempo:  30 dias | F1-score: 0.5379\n",
            "3¬∫ lugar | Tempo: 120 dias | F1-score: 0.4617\n",
            "4¬∫ lugar | Tempo: 150 dias | F1-score: 0.4545\n",
            "5¬∫ lugar | Tempo: 180 dias | F1-score: 0.4545\n",
            "6¬∫ lugar | Tempo: 210 dias | F1-score: 0.4545\n",
            "7¬∫ lugar | Tempo:  60 dias | F1-score: 0.4404\n",
            "\n",
            "==== Modelo: Naive Bayes ====\n",
            "1¬∫ lugar | Tempo:  60 dias | F1-score: 0.5861\n",
            "2¬∫ lugar | Tempo:  30 dias | F1-score: 0.5781\n",
            "3¬∫ lugar | Tempo:  90 dias | F1-score: 0.5733\n",
            "4¬∫ lugar | Tempo: 120 dias | F1-score: 0.5295\n",
            "5¬∫ lugar | Tempo: 150 dias | F1-score: 0.4884\n",
            "6¬∫ lugar | Tempo: 180 dias | F1-score: 0.4884\n",
            "7¬∫ lugar | Tempo: 210 dias | F1-score: 0.4884\n",
            "\n",
            "==== Modelo: KNN ====\n",
            "1¬∫ lugar | Tempo:  30 dias | F1-score: 0.5272\n",
            "2¬∫ lugar | Tempo: 120 dias | F1-score: 0.5266\n",
            "3¬∫ lugar | Tempo:  60 dias | F1-score: 0.5200\n",
            "4¬∫ lugar | Tempo:  90 dias | F1-score: 0.5081\n",
            "5¬∫ lugar | Tempo: 150 dias | F1-score: 0.4888\n",
            "6¬∫ lugar | Tempo: 180 dias | F1-score: 0.4888\n",
            "7¬∫ lugar | Tempo: 210 dias | F1-score: 0.4888\n",
            "\n",
            "==== Modelo: Gradient Boosting ====\n",
            "1¬∫ lugar | Tempo:  90 dias | F1-score: 0.4829\n",
            "2¬∫ lugar | Tempo: 120 dias | F1-score: 0.4771\n",
            "3¬∫ lugar | Tempo: 150 dias | F1-score: 0.4626\n",
            "4¬∫ lugar | Tempo: 180 dias | F1-score: 0.4626\n",
            "5¬∫ lugar | Tempo: 210 dias | F1-score: 0.4626\n",
            "6¬∫ lugar | Tempo:  30 dias | F1-score: 0.4399\n",
            "7¬∫ lugar | Tempo:  60 dias | F1-score: 0.3745\n",
            "\n",
            "==== Modelo: AdaBoost ====\n",
            "1¬∫ lugar | Tempo: 120 dias | F1-score: 0.5631\n",
            "2¬∫ lugar | Tempo:  90 dias | F1-score: 0.5538\n",
            "3¬∫ lugar | Tempo: 150 dias | F1-score: 0.5435\n",
            "4¬∫ lugar | Tempo: 180 dias | F1-score: 0.5435\n",
            "5¬∫ lugar | Tempo: 210 dias | F1-score: 0.5435\n",
            "6¬∫ lugar | Tempo:  60 dias | F1-score: 0.3919\n",
            "7¬∫ lugar | Tempo:  30 dias | F1-score: 0.3232\n",
            "\n",
            "==== Modelo: HistGradientBoosting ====\n",
            "1¬∫ lugar | Tempo: 150 dias | F1-score: 0.6058\n",
            "2¬∫ lugar | Tempo: 180 dias | F1-score: 0.6058\n",
            "3¬∫ lugar | Tempo: 210 dias | F1-score: 0.6058\n",
            "4¬∫ lugar | Tempo:  90 dias | F1-score: 0.5359\n",
            "5¬∫ lugar | Tempo:  30 dias | F1-score: 0.4912\n",
            "6¬∫ lugar | Tempo:  60 dias | F1-score: 0.4865\n",
            "7¬∫ lugar | Tempo: 120 dias | F1-score: 0.4397\n",
            "\n",
            "==== Modelo: RidgeClassifier ====\n",
            "1¬∫ lugar | Tempo:  60 dias | F1-score: 0.3806\n",
            "2¬∫ lugar | Tempo: 120 dias | F1-score: 0.3609\n",
            "3¬∫ lugar | Tempo:  30 dias | F1-score: 0.3571\n",
            "4¬∫ lugar | Tempo:  90 dias | F1-score: 0.3571\n",
            "5¬∫ lugar | Tempo: 150 dias | F1-score: 0.2971\n",
            "6¬∫ lugar | Tempo: 180 dias | F1-score: 0.2971\n",
            "7¬∫ lugar | Tempo: 210 dias | F1-score: 0.2971\n",
            "\n",
            "==== Modelo: XGBoost ====\n",
            "1¬∫ lugar | Tempo:  90 dias | F1-score: 0.6575\n",
            "2¬∫ lugar | Tempo: 150 dias | F1-score: 0.6031\n",
            "3¬∫ lugar | Tempo: 180 dias | F1-score: 0.6031\n",
            "4¬∫ lugar | Tempo: 210 dias | F1-score: 0.6031\n",
            "5¬∫ lugar | Tempo: 120 dias | F1-score: 0.6006\n",
            "6¬∫ lugar | Tempo:  30 dias | F1-score: 0.5792\n",
            "7¬∫ lugar | Tempo:  60 dias | F1-score: 0.4872\n",
            "\n",
            "==== Modelo: CatBoost ====\n",
            "1¬∫ lugar | Tempo:  90 dias | F1-score: 0.5044\n",
            "2¬∫ lugar | Tempo:  30 dias | F1-score: 0.4976\n",
            "3¬∫ lugar | Tempo: 120 dias | F1-score: 0.4651\n",
            "4¬∫ lugar | Tempo:  60 dias | F1-score: 0.4363\n",
            "5¬∫ lugar | Tempo: 150 dias | F1-score: 0.3521\n",
            "6¬∫ lugar | Tempo: 180 dias | F1-score: 0.3521\n",
            "7¬∫ lugar | Tempo: 210 dias | F1-score: 0.3521\n",
            "\n",
            "==== Ranking geral (todos os modelos e per√≠odos) ====\n",
            "1¬∫ lugar | Modelo: Regress√£o Log√≠stica | Tempo:  90 dias | F1-score: 0.6988\n",
            "2¬∫ lugar | Modelo: Regress√£o Log√≠stica | Tempo: 120 dias | F1-score: 0.6979\n",
            "3¬∫ lugar | Modelo: Regress√£o Log√≠stica | Tempo:  30 dias | F1-score: 0.6961\n",
            "4¬∫ lugar | Modelo: Regress√£o Log√≠stica | Tempo: 150 dias | F1-score: 0.6951\n",
            "5¬∫ lugar | Modelo: Regress√£o Log√≠stica | Tempo: 180 dias | F1-score: 0.6951\n",
            "6¬∫ lugar | Modelo: Regress√£o Log√≠stica | Tempo: 210 dias | F1-score: 0.6951\n",
            "7¬∫ lugar | Modelo: Regress√£o Log√≠stica | Tempo:  60 dias | F1-score: 0.6811\n",
            "8¬∫ lugar | Modelo: √Årvore de Decis√£o | Tempo:  90 dias | F1-score: 0.6613\n",
            "9¬∫ lugar | Modelo: XGBoost | Tempo:  90 dias | F1-score: 0.6575\n",
            "10¬∫ lugar | Modelo: HistGradientBoosting | Tempo: 150 dias | F1-score: 0.6058\n",
            "11¬∫ lugar | Modelo: HistGradientBoosting | Tempo: 180 dias | F1-score: 0.6058\n",
            "12¬∫ lugar | Modelo: HistGradientBoosting | Tempo: 210 dias | F1-score: 0.6058\n",
            "13¬∫ lugar | Modelo: XGBoost | Tempo: 150 dias | F1-score: 0.6031\n",
            "14¬∫ lugar | Modelo: XGBoost | Tempo: 180 dias | F1-score: 0.6031\n",
            "15¬∫ lugar | Modelo: XGBoost | Tempo: 210 dias | F1-score: 0.6031\n",
            "16¬∫ lugar | Modelo: XGBoost | Tempo: 120 dias | F1-score: 0.6006\n",
            "17¬∫ lugar | Modelo: Naive Bayes | Tempo:  60 dias | F1-score: 0.5861\n",
            "18¬∫ lugar | Modelo: XGBoost | Tempo:  30 dias | F1-score: 0.5792\n",
            "19¬∫ lugar | Modelo: Naive Bayes | Tempo:  30 dias | F1-score: 0.5781\n",
            "20¬∫ lugar | Modelo: Naive Bayes | Tempo:  90 dias | F1-score: 0.5733\n",
            "21¬∫ lugar | Modelo: AdaBoost | Tempo: 120 dias | F1-score: 0.5631\n",
            "22¬∫ lugar | Modelo: Random Forest | Tempo:  90 dias | F1-score: 0.5613\n",
            "23¬∫ lugar | Modelo: AdaBoost | Tempo:  90 dias | F1-score: 0.5538\n",
            "24¬∫ lugar | Modelo: AdaBoost | Tempo: 150 dias | F1-score: 0.5435\n",
            "25¬∫ lugar | Modelo: AdaBoost | Tempo: 180 dias | F1-score: 0.5435\n",
            "26¬∫ lugar | Modelo: AdaBoost | Tempo: 210 dias | F1-score: 0.5435\n",
            "27¬∫ lugar | Modelo: Random Forest | Tempo:  30 dias | F1-score: 0.5379\n",
            "28¬∫ lugar | Modelo: HistGradientBoosting | Tempo:  90 dias | F1-score: 0.5359\n",
            "29¬∫ lugar | Modelo: √Årvore de Decis√£o | Tempo:  30 dias | F1-score: 0.5351\n",
            "30¬∫ lugar | Modelo: Naive Bayes | Tempo: 120 dias | F1-score: 0.5295\n",
            "31¬∫ lugar | Modelo: KNN | Tempo:  30 dias | F1-score: 0.5272\n",
            "32¬∫ lugar | Modelo: KNN | Tempo: 120 dias | F1-score: 0.5266\n",
            "33¬∫ lugar | Modelo: KNN | Tempo:  60 dias | F1-score: 0.5200\n",
            "34¬∫ lugar | Modelo: KNN | Tempo:  90 dias | F1-score: 0.5081\n",
            "35¬∫ lugar | Modelo: CatBoost | Tempo:  90 dias | F1-score: 0.5044\n",
            "36¬∫ lugar | Modelo: CatBoost | Tempo:  30 dias | F1-score: 0.4976\n",
            "37¬∫ lugar | Modelo: HistGradientBoosting | Tempo:  30 dias | F1-score: 0.4912\n",
            "38¬∫ lugar | Modelo: KNN | Tempo: 150 dias | F1-score: 0.4888\n",
            "39¬∫ lugar | Modelo: KNN | Tempo: 180 dias | F1-score: 0.4888\n",
            "40¬∫ lugar | Modelo: KNN | Tempo: 210 dias | F1-score: 0.4888\n",
            "41¬∫ lugar | Modelo: Naive Bayes | Tempo: 150 dias | F1-score: 0.4884\n",
            "42¬∫ lugar | Modelo: Naive Bayes | Tempo: 180 dias | F1-score: 0.4884\n",
            "43¬∫ lugar | Modelo: Naive Bayes | Tempo: 210 dias | F1-score: 0.4884\n",
            "44¬∫ lugar | Modelo: XGBoost | Tempo:  60 dias | F1-score: 0.4872\n",
            "45¬∫ lugar | Modelo: HistGradientBoosting | Tempo:  60 dias | F1-score: 0.4865\n",
            "46¬∫ lugar | Modelo: Gradient Boosting | Tempo:  90 dias | F1-score: 0.4829\n",
            "47¬∫ lugar | Modelo: √Årvore de Decis√£o | Tempo: 120 dias | F1-score: 0.4804\n",
            "48¬∫ lugar | Modelo: Gradient Boosting | Tempo: 120 dias | F1-score: 0.4771\n",
            "49¬∫ lugar | Modelo: CatBoost | Tempo: 120 dias | F1-score: 0.4651\n",
            "50¬∫ lugar | Modelo: Gradient Boosting | Tempo: 150 dias | F1-score: 0.4626\n",
            "51¬∫ lugar | Modelo: Gradient Boosting | Tempo: 180 dias | F1-score: 0.4626\n",
            "52¬∫ lugar | Modelo: Gradient Boosting | Tempo: 210 dias | F1-score: 0.4626\n",
            "53¬∫ lugar | Modelo: Random Forest | Tempo: 120 dias | F1-score: 0.4617\n",
            "54¬∫ lugar | Modelo: √Årvore de Decis√£o | Tempo: 150 dias | F1-score: 0.4579\n",
            "55¬∫ lugar | Modelo: √Årvore de Decis√£o | Tempo: 180 dias | F1-score: 0.4579\n",
            "56¬∫ lugar | Modelo: √Årvore de Decis√£o | Tempo: 210 dias | F1-score: 0.4579\n",
            "57¬∫ lugar | Modelo: Random Forest | Tempo: 150 dias | F1-score: 0.4545\n",
            "58¬∫ lugar | Modelo: Random Forest | Tempo: 180 dias | F1-score: 0.4545\n",
            "59¬∫ lugar | Modelo: Random Forest | Tempo: 210 dias | F1-score: 0.4545\n",
            "60¬∫ lugar | Modelo: Random Forest | Tempo:  60 dias | F1-score: 0.4404\n",
            "61¬∫ lugar | Modelo: Gradient Boosting | Tempo:  30 dias | F1-score: 0.4399\n",
            "62¬∫ lugar | Modelo: HistGradientBoosting | Tempo: 120 dias | F1-score: 0.4397\n",
            "63¬∫ lugar | Modelo: CatBoost | Tempo:  60 dias | F1-score: 0.4363\n",
            "64¬∫ lugar | Modelo: √Årvore de Decis√£o | Tempo:  60 dias | F1-score: 0.4282\n",
            "65¬∫ lugar | Modelo: AdaBoost | Tempo:  60 dias | F1-score: 0.3919\n",
            "66¬∫ lugar | Modelo: RidgeClassifier | Tempo:  60 dias | F1-score: 0.3806\n",
            "67¬∫ lugar | Modelo: Gradient Boosting | Tempo:  60 dias | F1-score: 0.3745\n",
            "68¬∫ lugar | Modelo: RidgeClassifier | Tempo: 120 dias | F1-score: 0.3609\n",
            "69¬∫ lugar | Modelo: RidgeClassifier | Tempo:  30 dias | F1-score: 0.3571\n",
            "70¬∫ lugar | Modelo: RidgeClassifier | Tempo:  90 dias | F1-score: 0.3571\n",
            "71¬∫ lugar | Modelo: CatBoost | Tempo: 150 dias | F1-score: 0.3521\n",
            "72¬∫ lugar | Modelo: CatBoost | Tempo: 180 dias | F1-score: 0.3521\n",
            "73¬∫ lugar | Modelo: CatBoost | Tempo: 210 dias | F1-score: 0.3521\n",
            "74¬∫ lugar | Modelo: AdaBoost | Tempo:  30 dias | F1-score: 0.3232\n",
            "75¬∫ lugar | Modelo: RidgeClassifier | Tempo: 150 dias | F1-score: 0.2971\n",
            "76¬∫ lugar | Modelo: RidgeClassifier | Tempo: 180 dias | F1-score: 0.2971\n",
            "77¬∫ lugar | Modelo: RidgeClassifier | Tempo: 210 dias | F1-score: 0.2971\n",
            "78¬∫ lugar | Modelo: Dummy (mais frequente) | Tempo:  30 dias | F1-score: 0.0000\n",
            "79¬∫ lugar | Modelo: Dummy (mais frequente) | Tempo:  60 dias | F1-score: 0.0000\n",
            "80¬∫ lugar | Modelo: Dummy (mais frequente) | Tempo:  90 dias | F1-score: 0.0000\n",
            "81¬∫ lugar | Modelo: Dummy (mais frequente) | Tempo: 120 dias | F1-score: 0.0000\n",
            "82¬∫ lugar | Modelo: Dummy (mais frequente) | Tempo: 150 dias | F1-score: 0.0000\n",
            "83¬∫ lugar | Modelo: Dummy (mais frequente) | Tempo: 180 dias | F1-score: 0.0000\n",
            "84¬∫ lugar | Modelo: Dummy (mais frequente) | Tempo: 210 dias | F1-score: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# @title Compara√ß√£o de resultados\n",
        "\n",
        "resultados_por_modelo = {}\n",
        "\n",
        "# Agrupa os resultados por modelo\n",
        "for entrada in resultados_gerais:\n",
        "    nome_modelo = entrada[\"Modelo\"]\n",
        "    if nome_modelo not in resultados_por_modelo:\n",
        "        resultados_por_modelo[nome_modelo] = []\n",
        "    resultados_por_modelo[nome_modelo].append(entrada)\n",
        "\n",
        "# Ordena os resultados de cada modelo\n",
        "for nome_modelo, lista_resultados in resultados_por_modelo.items():\n",
        "    lista_ordenada = sorted(\n",
        "        lista_resultados,\n",
        "        key=lambda x: x[\"F1-score\"],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    print(f\"\\n==== Modelo: {nome_modelo} ====\")\n",
        "    for posicao, item in enumerate(lista_ordenada, start=1):\n",
        "        print(f\"{posicao}¬∫ lugar | Tempo: {item['Tempo']:>3} dias | F1-score: {item['F1-score']:.4f}\")\n",
        "\n",
        "# Ordena os resultados de maneira gerais\n",
        "resultados_gerais_ordenados = sorted(\n",
        "    resultados_gerais,\n",
        "    key=lambda x: x[\"F1-score\"],\n",
        "    reverse=True\n",
        ")\n",
        "\n",
        "print(\"\\n==== Ranking geral (todos os modelos e per√≠odos) ====\")\n",
        "for posicao, item in enumerate(resultados_gerais_ordenados, start=1):\n",
        "    print(f\"{posicao}¬∫ lugar | Modelo: {item['Modelo']} | Tempo: {item['Tempo']:>3} dias | F1-score: {item['F1-score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O modelo escolhido foi a **Regress√£o Log√≠stica**.\n",
        "\n",
        "Justificativas para a escolha:\n",
        "- Ele apresentou o **melhor F1-score** entre todos os modelos avaliados, indicando melhor equil√≠brio entre precis√£o e recall.\n",
        "- Tamb√©m teve **alta AUC-ROC**, mostrando excelente separa√ß√£o entre classes.\n",
        "- Com o par√¢metro `class_weight='balanced'`, lidou bem com o desbalanceamento da base de inc√™ndios (poucos inc√™ndios vs muitos \"n√£o inc√™ndios\").\n",
        "- √â um modelo **interpret√°vel**, ideal para aplicar t√©cnicas de explicabilidade\n",
        "- Seus coeficientes permitem identificar claramente a influ√™ncia das vari√°veis, atendendo √† tarefa de \"Aplicar algoritmos para ajudar a explicar as decis√µes do modelo\".\n",
        "\n",
        "<b>Explicabilidade do modelo</b>\n",
        "A t√©cnica usada aqui √© a an√°lise dos **coeficientes** da Regress√£o Log√≠stica.\n",
        "Interpreta√ß√£o: \n",
        "- Coeficientes POSITIVOS aumentam a probabilidade de inc√™ndio.\n",
        "- Coeficientes NEGATIVOS reduzem essa probabilidade.\n",
        "- Quanto maior o valor absoluto do coeficiente, maior a import√¢ncia da vari√°vel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Shape of passed values is (312975, 16), indices imply (312975, 17)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Corrige nomes das colunas (baseado no DataFrame original)\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Se quiser nomes mais claros, use as colunas do dataset filtrado:\u001b[39;00m\n\u001b[32m     21\u001b[39m colunas_numericas = features.select_dtypes(include=\u001b[33m'\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m'\u001b[39m).columns\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m X_preprocessado_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_preprocessado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolunas_numericas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Extrai os coeficientes da regress√£o log√≠stica\u001b[39;00m\n\u001b[32m     25\u001b[39m modelo = pipeline.named_steps[\u001b[33m\"\u001b[39m\u001b[33mclassificator\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:831\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    820\u001b[39m         mgr = dict_to_mgr(\n\u001b[32m    821\u001b[39m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[32m    822\u001b[39m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    828\u001b[39m             copy=_copy,\n\u001b[32m    829\u001b[39m         )\n\u001b[32m    830\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m831\u001b[39m         mgr = \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[39m, in \u001b[36mndarray_to_mgr\u001b[39m\u001b[34m(values, index, columns, dtype, copy, typ)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[32m    332\u001b[39m index, columns = _get_axes(\n\u001b[32m    333\u001b[39m     values.shape[\u001b[32m0\u001b[39m], values.shape[\u001b[32m1\u001b[39m], index=index, columns=columns\n\u001b[32m    334\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[39m, in \u001b[36m_check_values_indices_shape_match\u001b[39m\u001b[34m(values, index, columns)\u001b[39m\n\u001b[32m    418\u001b[39m passed = values.shape\n\u001b[32m    419\u001b[39m implied = (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mValueError\u001b[39m: Shape of passed values is (312975, 16), indices imply (312975, 17)"
          ]
        }
      ],
      "source": [
        "# @title Algoritmos para explicar as decis√µes do modelo\n",
        "\n",
        "# Define e treina o pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess),  # j√° criado no projeto\n",
        "    (\"nan_shield\", SimpleImputer(strategy=\"constant\", fill_value=0.0)),\n",
        "    (\"classificator\", LogisticRegression(\n",
        "        C=0.5, penalty='l2', solver='liblinear',\n",
        "        max_iter=2000, class_weight='balanced'\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Treina o modelo com os dados\n",
        "pipeline.fit(features, target)\n",
        "\n",
        "# Aplica o pr√©-processamento\n",
        "X_preprocessado = pipeline.named_steps[\"preprocess\"].transform(features)\n",
        "\n",
        "# Corrige nomes das colunas (baseado no DataFrame original)\n",
        "# Se quiser nomes mais claros, use as colunas do dataset filtrado:\n",
        "colunas_numericas = features.select_dtypes(include='number').columns\n",
        "X_preprocessado_df = pd.DataFrame(X_preprocessado, columns=colunas_numericas)\n",
        "\n",
        "# Extrai os coeficientes da regress√£o log√≠stica\n",
        "modelo = pipeline.named_steps[\"classificator\"]\n",
        "coeficientes = pd.Series(modelo.coef_[0], index=X_preprocessado_df.columns)\n",
        "\n",
        "# Ordena pelos mais influentes (positiva ou negativamente)\n",
        "coef_ordenados = coeficientes.sort_values(key=np.abs, ascending=False)\n",
        "\n",
        "# Exibe as 10 vari√°veis mais influentes\n",
        "print(\" Top 10 vari√°veis que mais influenciam a decis√£o do modelo:\")\n",
        "print(coef_ordenados.head(10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
